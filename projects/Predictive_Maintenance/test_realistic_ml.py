#!/usr/bin/env python3
"""
Test script for Realistic ML Model Training with Incremental Learning
"""

import requests
import time
import json

API_BASE = "http://localhost:5001/api"

def test_realistic_ml_training():
    """Test realistic ML training with incremental learning"""
    print("üß† Testing Realistic ML Training with Incremental Learning")
    print("=" * 60)
    
    try:
        # Test training with 7 days of data (incremental learning)
        print("üîÑ Training models with last 7 days of sensor data...")
        response = requests.post(f"{API_BASE}/ml/train", 
                               json={"days_back": 7})
        
        print(f"Training response status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Training successful: {data['message']}")
            
            # Check validation info
            if 'validation_info' in data:
                print("\nüìä Validation Methods Used:")
                for method, used in data['validation_info'].items():
                    if used:
                        print(f"  ‚úÖ {method.replace('_', ' ').title()}")
            
            # Check warnings
            if 'warnings' in data and data['warnings']:
                print("\n‚ö†Ô∏è  Model Validation Warnings:")
                for warning in data['warnings']:
                    print(f"  ‚Ä¢ {warning}")
            
            # Display realistic performance metrics
            if 'performance' in data:
                performance = data['performance']
                
                print("\nüìà Health Model Performance:")
                health_perf = performance['health_model']
                print(f"  ‚Ä¢ MSE: {health_perf['mse']:.4f}")
                print(f"  ‚Ä¢ R¬≤: {health_perf['r2']:.4f}")
                print(f"  ‚Ä¢ CV Score: {health_perf['cv_score_mean']:.4f} ¬± {health_perf['cv_score_std']:.4f}")
                print(f"  ‚Ä¢ Training Samples: {health_perf['training_samples']}")
                
                print("\n‚ö†Ô∏è  Failure Model Performance:")
                failure_perf = performance['failure_model']
                print(f"  ‚Ä¢ Accuracy: {failure_perf['accuracy']:.4f}")
                print(f"  ‚Ä¢ Precision: {failure_perf['precision']:.4f}")
                print(f"  ‚Ä¢ Recall: {failure_perf['recall']:.4f}")
                print(f"  ‚Ä¢ F1 Score: {failure_perf['f1_score']:.4f}")
                print(f"  ‚Ä¢ CV Score: {failure_perf['cv_score_mean']:.4f} ¬± {failure_perf['cv_score_std']:.4f}")
                print(f"  ‚Ä¢ Training Samples: {failure_perf['training_samples']}")
            
            return True
        else:
            print(f"‚ùå Training failed: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def test_incremental_retraining():
    """Test incremental retraining with new data"""
    print("\nüîÑ Testing Incremental Retraining")
    print("=" * 40)
    
    try:
        # Wait a bit to simulate new data coming in
        print("‚è≥ Waiting for new sensor data...")
        time.sleep(2)
        
        # Retrain with new data
        response = requests.post(f"{API_BASE}/ml/retrain", 
                               json={"days_back": 7})
        
        print(f"Retraining response status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Retraining result: {data['message']}")
            
            if 'warnings' in data and data['warnings']:
                print("\n‚ö†Ô∏è  Validation Warnings:")
                for warning in data['warnings']:
                    print(f"  ‚Ä¢ {warning}")
            
            return True
        else:
            print(f"‚ùå Retraining failed: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def test_realistic_predictions():
    """Test predictions with realistic accuracy"""
    print("\nüéØ Testing Realistic Predictions")
    print("=" * 40)
    
    try:
        # Test with different sensor data scenarios
        test_cases = [
            {
                "name": "Normal Operation",
                "sensor_data": {"temperature": 70.0, "vibration": 1.5, "pressure": 20.0, "rpm": 1800}
            },
            {
                "name": "High Temperature",
                "sensor_data": {"temperature": 85.0, "vibration": 2.0, "pressure": 22.0, "rpm": 1900}
            },
            {
                "name": "High Vibration",
                "sensor_data": {"temperature": 75.0, "vibration": 3.5, "pressure": 18.0, "rpm": 1750}
            }
        ]
        
        for test_case in test_cases:
            print(f"\nüìä Testing: {test_case['name']}")
            
            response = requests.post(f"{API_BASE}/ml/predict", 
                                   json={"sensor_data": test_case['sensor_data']})
            
            if response.status_code == 200:
                data = response.json()
                predictions = data['predictions']
                
                print(f"  ‚Ä¢ Health Score: {predictions['health_score']:.2f}%")
                print(f"  ‚Ä¢ Failure Probability: {predictions['failure_probability']:.2f}%")
                
                # Validate that predictions are realistic
                if predictions['health_score'] < 0 or predictions['health_score'] > 100:
                    print(f"  ‚ö†Ô∏è  Warning: Health score out of range!")
                
                if predictions['failure_probability'] < 0 or predictions['failure_probability'] > 100:
                    print(f"  ‚ö†Ô∏è  Warning: Failure probability out of range!")
            else:
                print(f"  ‚ùå Prediction failed: {response.text}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def test_model_validation():
    """Test model validation and performance monitoring"""
    print("\nüîç Testing Model Validation")
    print("=" * 40)
    
    try:
        # Get model status with validation info
        response = requests.get(f"{API_BASE}/ml/status")
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Model Status Retrieved")
            
            # Check validation info
            if 'validation_info' in data:
                print("\nüìä Validation Methods:")
                for method, used in data['validation_info'].items():
                    if used:
                        print(f"  ‚úÖ {method.replace('_', ' ').title()}")
            
            # Check warnings
            if 'warnings' in data and data['warnings']:
                print("\n‚ö†Ô∏è  Model Warnings:")
                for warning in data['warnings']:
                    print(f"  ‚Ä¢ {warning}")
            else:
                print("\n‚úÖ No model validation warnings")
            
            return True
        else:
            print(f"‚ùå Status check failed: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def main():
    print("üéØ Realistic ML Training & Validation Test Suite")
    print("=" * 70)
    print("Testing incremental learning, realistic accuracy, and proper validation")
    print("=" * 70)
    
    try:
        # Test realistic ML training
        training_success = test_realistic_ml_training()
        
        # Test incremental retraining
        retraining_success = test_incremental_retraining()
        
        # Test realistic predictions
        prediction_success = test_realistic_predictions()
        
        # Test model validation
        validation_success = test_model_validation()
        
        print("\n" + "=" * 70)
        if training_success and retraining_success and prediction_success and validation_success:
            print("üéâ REALISTIC ML TESTS COMPLETED!")
            print("‚úÖ Incremental learning with new sensor data")
            print("‚úÖ Cross-validation and realistic accuracy reporting")
            print("‚úÖ Model validation warnings and monitoring")
            print("‚úÖ Proper performance metrics (no 100% accuracy)")
            print("\nüöÄ Ready for realistic hackathon demo!")
        else:
            print("‚ùå SOME REALISTIC ML TESTS FAILED")
            print("Check the error messages above for details")
        
    except Exception as e:
        print(f"\n‚ùå TEST SUITE FAILED: {e}")
        return False
    
    return True

if __name__ == "__main__":
    main()
